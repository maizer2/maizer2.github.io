---
layout: post
title: "평균 제곱근 오차, RMSE"
categories: [1. Computer Engineering]
tags: [1.2. Artificial Intelligence, 1.2.1. Machine Learning, a.b. Regression Problem]
---
### 평균 제곱근 오차 (RMSE, Root Mean Square Error)

#### [핸즈온 머신러닝 2](https://tensorflow.blog/핸즈온-머신러닝-1장-2장/2-2-큰-그림-보기/)

회귀 문제의 전형적인 성능 지표로서 오차가 커질수록 값이 커짐으로서 얼마나 많은 오류가 있는지 가늠하게 해준다.

#### [wikipedia](https://ko.wikipedia.org/wiki/평균_제곱근_편차)

추정 값 또는 모델이 예측한 값과 실제 환경에서 관찰되는 값의 차이를 다룰 때 흔히 사용되는 측도이다.


### RMSE 식

$$ RMSE(\hat{\theta}) = \sqrt{MSE(\hat{\theta})} = \sqrt{E((\hat{\theta}-\theta)^2)}\; \;, \; \; \; \; 
\theta_{1} = \begin{bmatrix} 
x_{1, 1} \\
x_{1, 2} \\
\vdots \\
x_{1, n}\end{bmatrix} \; \; \; \; and \; \; \; \; \theta_{2} = \begin{bmatrix} 
x_{2, 1} \\
x_{2, 2} \\
\vdots \\
x_{2, n}\end{bmatrix} $$

$$ RMSE(\theta_{1}, \theta_{2}) = \sqrt{MSE(\theta_{1}, \theta_{2})} = \sqrt{E((\theta_{1} - \theta_{2})^2)} = \sqrt{\frac{\sum_{i=1}^{n}(x_{1, i} - x_{2, i})^2}{n}}. $$

--- 

#### 해석

위 식은 처음 보면 어려울 수 있어 핸즈온 머신러닝 2에 써져있는 수식을 가져와서 쓰겠다.

$$ RMSE(X, h) = \sqrt{\frac{1}{m}\sum_{i=1}^{m}(h(x^i)-y^i)^2} $$

* X = 데이터셋에 있는 모든 샘플의 모든 특성값을 포함하는 행렬  
* m = 데이터셋 샘플 수
* $ x^{i} $ 는 데이터셋에 있는 i번째 샘플의 전체 특성값의 벡터이다.
* $ y^{i} $ 는 해당 레이블(해당 샘플의 기대 출력값)이다.
* h = 시스템의 ***예측 함수***이며 가설이라고도 한다. 
  * $ h(x^{i}) $ 은 $ x^{i} $ 벡터를 예측 함수에 넣었을 때 출력하는 ***예측값***이다.

$$ h(x^{(i)}) = \hat{y}^{(i)} \;\; , \;\;\;\; \sqrt{\frac{1}{m}\sum_{i=1}^{m}(\hat{y}^{(i)}-y^{(i)})^{2}} $$

$ \hat{y}^{(i)} $ 는 에측 값이며 $ y^{(i)} $ 는 기대 출력값이다.  
두 값을 빼면 예측 오차를 얻을 수 있다.

따라서 예측 오차가 커질수록 1부터 m 까지(모든 샘플 수) 예측 오차의 합의 제곱은 더욱 커진다.

---

##### 참고문헌

1) wikipedia, 평균 제곱근 편차, [https://ko.wikipedia.org/wiki/평균_제곱근_편차](https://ko.wikipedia.org/wiki/평균_제곱근_편차)
