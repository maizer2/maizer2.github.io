---
layout: post
title: "AutoEncoder"
categories: [1. Computer Engineering]
tags: [1.2. Artificial Intelligence, 1.2.2.1. Computer Vision]
---

### AutoEncoder란?

입력 데이터의 특성을 추출하여 입력 데이터와 비슷한 데이터를 재현(복원)한다.

<center><img alt="AutoEncoder" src="https://blog.keras.io/img/ae/autoencoder_schema.jpg"></center>

<center>AutoEncoder 추상화<sup><a href="#footnote_2_1" name="footnote_2_2">[2]</a></sup></center><br/>


### AutoEncoder 특징

1. UnSupervised Learning
    * 입력값 $x$을 label로 사용하여 label을 필요로하지 않는다.

2. [Manifold Learning](https://maizer2.github.io/1.%20computer%20engineering/2023-06-23-manifold-learning.html)
    * Encoder<sup>Feature extract</sup> 결과를 통해 입력 데이터의 차원 축소가 발생한다.

3. Generation Model
    * 압축 데이터를 원본 이미지와 같이 생성한다.


### AutoEncoder의 이론적 설명

<center><img width="800" alt="AutoEncoder" src="https://raw.githubusercontent.com/maizer2/gitblog_img/main/1.%20Computer%20Engineering/1.2.%20Artificial%20Intelligence/2022-03-29-AutoEncoder/AutoEncoder.PNG"></center>

<center>AutoEncoder $E(x)\to z \to D(z) \to \hat{x}$</center><br/>

AutoEncoder는 Encoder의 데이터 압축을 위한 모델이다.

압축된 데이터를 latent variable이라고 표현하는데, latent variable이 속한 공간을 latent space라고 표현한다.

Encoder를 통해 압축된 데이터를 Decoder를 통해 원본 이미지와 같이 복원할 수 있음을 보여준 모델이다.

### AutoEncoder Loss function

$$ h(.) = Encoder(.) $$

$$ g(.) = Decoder(.) $$

$$ \hat{x} = g(h(x))$$

$$ L_{AE}(x, \hat{x}) = \vert{}\vert{} x - \hat{x} \vert{}\vert{}^2 $$

여기서 Loss Function은 Mean Squared Function<sup>MSE</sup>과 동일하다.