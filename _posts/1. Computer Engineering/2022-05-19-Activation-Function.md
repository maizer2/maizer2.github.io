---
layout: post
title: "Activation Function"
categories: [1. Computer Engineering]
tags: [1.2. Artificial Intelligence, 1.2.1. Machine Learning, 1.2.2. Deep Learning]
---

[When use Activation Function](https://maizer2.github.io/1.%20computer%20engineering/2022/05/19/Functions-used-in-each-layer-in-artificial-neural-networks.html)

### Introduction

Activation Function은 Forward prapagation의 출력값을 특정 범위로 조정해주는 Fucntion이다

> 참고 : [Three basic output of ANN](https://maizer2.github.io/1.%20computer%20engineering/2022/05/19/Activation-Function.html)

Activation Function은 출력하고자 하는 결과값에 따라 선택하여 쓸 수 있다.

### Kind of Activation Function

* Step Function
* Sign Function
* Sigmoid Function
* Hyperbolic Tangent, tanh
* ReLU, Rectified Linear Unit
* Leaky ReLU
* Identity function

### Sign of Activation Function

$$ \phi(x) $$