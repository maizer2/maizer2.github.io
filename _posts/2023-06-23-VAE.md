---
layout: post
title: "Variational AutoEncoder"
categories: [1. Computer Engineering]
tags: [1.2. Artificial Intelligence, 1.2.2.4. VAE, a.b. UnSupervised Learning]
---

![VAE](https://user-images.githubusercontent.com/24144491/50323466-18d03700-051d-11e9-82ed-afb1b6e2666a.png)

<center>Variational AutoEncoder<sup><a href="#footnote_1_1" name="footnote_1_2">[2]</a></sup></center><br/>

### Variational AutoEncoder란?

* AutoEncoder<sup>AE</sup>와 동일하게 입력 데이터를 재현(복원)한다.

* 하지만 AE는 입력 데이터를 Encoder를 통해 Latent vector로 만드는 압축 방식을 하였다면, Variational AutoEncoder<sup>VAE</sup>는 입력 데이터의 Encoder 결과로 평균과 분산을 얻어, 입력 데이터의 분포를 얻게 되는 차이점이 있다.

* VAE는 Encoder를 통해 얻은 분포를 사용하여 latent vector $z$를 sampling하게 되는데, 이과정은 역전파가 불가능해 기울기 계산을 할 수 없다.

* 미분 가능하게 하기 위해 Reparameterization Trick을 사용해 미분 가능하게 하였다.

* VAE는 Encoder를 위해 개발된 AE와 다르게 Decoder를 사용하기 위해 개발된 모델이다.


### VAE 이론적 설명

VAE의 배경은 "latent variable 이하 $z$를 사용하여 이미지를 생성한다." 에서 시작한다.

$z$의 확률 분포를 $p_{\theta}(z)$라고 할 때, 생성하려고 하는 이미지의 확률 분포 $p(x)$를 구하는 조건부 확률은 $p_{\theta}(x\vert{}z)$와 같다.

우리가


### AutoEncoder Loss function


---

##### Reference

<a href="#footnote_1_2" name="footnote_1_1">1. </a> [논문] VAE(Auto-Encoding Variational Bayes) 직관적 이해, 20. 12. 2018, taeu.github.io, [https://taeu.github.io/paper/deeplearning-paper-vae/](https://taeu.github.io/paper/deeplearning-paper-vae/)